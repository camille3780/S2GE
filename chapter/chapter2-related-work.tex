\begin{ZhChapter}
    \chapter{Related Work}
    This section will introduce the relevant basic knowledge, including existing IoT network intrusion detection methods, tokenization, hash embedding, multi-layer perceptron, semantic vectors, and Mahalanobis distance.


    \section{Network Intrusion Detection System in IoT}
    In recent years, the rapid expansion of Internet of Things (IoT) devices has driven increased research attention towards designing effective network intrusion detection systems (NIDS) that address the unique challenges of IoT environments. These challenges include managing large volumes of heterogeneous traffic, coping with resource-constrained devices, and adapting to evolving attack patterns.

    Traditional machine learning algorithms such as Support Vector Machines (SVM), k-Nearest Neighbors (kNN), Decision Trees, and Random Forests~\cite{huang2025machine} have been widely adopted in early intrusion detection systems (IDS) due to their simplicity, interpretability, and relatively low computational requirements. These methods generally rely on handcrafted features and assume static data distributions, which limits their adaptability to evolving attack patterns. Moreover, the performance of such models heavily depends on feature selection quality and preprocessing strategies, making them less flexible in dynamic IoT environments.

    Several approaches have been proposed to tackle these issues. For instance, \citeauthor{kharoubi2025network} \cite{kharoubi2025network} developed a convolutional neural network (CNN)-based detection system tailored for IoT security. By leveraging CNN layers to extract spatial features from network traffic, their model achieved strong classification performance on benchmark datasets such as Canadian Institute for Cybersecurity Internet of Things (CICIoT2023)~\cite{ciciot2023} and Canadian Institute for Cybersecurity Internet of Medical Things (CICIoMT2024)~\cite{ciciot2024}. While demonstrating excellent precision and recall in both binary and multi-class scenarios, this approach has limitations in capturing temporal dependencies within packet sequences and requires large amounts of labeled data due to its supervised learning nature.

    Complementing deep learning methods, \citeauthor{ashraf2025making} \cite{ashraf2025making} proposed a real-time IoT Network Intrusion Detection System (INIDS) based on traditional machine learning classifiers, evaluated on the BoT-IoT dataset. Their comparative study of seven algorithms—including Random Forest, Artificial Neural Networks (ANN), and Support Vector Machines (SVM)—showed that Random Forest and ANN achieved superior accuracy and robustness. However, these models heavily rely on manual feature engineering and face challenges in adapting to novel threats, a crucial factor in the rapidly evolving IoT landscape.

    Recognizing the importance of feature design, \citeauthor{lee2000framework} \cite{lee2000framework} emphasized feature extraction techniques to build accurate and efficient intrusion detection models. Their work demonstrated that appropriate feature selection is vital, particularly when handling large datasets or emerging attack types.

    Together, these studies highlight the complementary strengths and limitations of various NIDS approaches in IoT, motivating the development of methods that balance automatic feature learning, temporal modeling, and adaptability to new threats.


    Table 2.1~\cite{geeksforgeeks} provides a consolidated overview of eight widely adopted features commonly utilized in anomaly detection across both academic research and industrial applications.


    \begin{table*}[htbp]
        \centering
        \caption{Common Anomalous Features in IoT Network Traffic}
        \label{tab:iot_abnormal_features}
        \vspace{0.5em}
        \makebox[\linewidth][c]{
            \renewcommand\arraystretch{1.3}{
                \begin{tabular}{| l | p{10cm} |}
                    \hline
                    \textbf{Feature}           & \textbf{Description}                                                                                                                        \\
                    \hline
                    Destination Port           &
                    The port number in a network packet received by the destination host, used to identify the communication entry point of an application or service.                       \\
                    \hline
                    Protocol Type              &
                    Used to indicate the type of communication protocol used by the packet, such as TCP, UDP, ICMP, etc.                                                                     \\
                    \hline
                    Duration / flow\_duration  & The length of time a network connection session lasts, the number of seconds from the start to the end of the connection.                   \\
                    \hline
                    Packet Length              &
                    The size of a packet is usually measured in bytes and refers to the amount of data in a single packet.                                                                   \\
                    \hline
                    Source IP / Destination IP &
                    The source and destination IP addresses of a packet indicate the network locations of the sender and receiver, respectively.                                             \\
                    \hline
                    Flow Bytes per Second      &
                    The total data flow through the network connection per unit time, measured in bytes per second (Bytes/s).                                                                \\
                    \hline
                    TCP Flags                  &
                    The control bit flag in the TCP packet indicates the status of the packet or the control message, such as SYN for connection request and FIN for connection termination. \\
                    \hline
                    Number of Connections      &
                    The number of network connections established by a single source IP within a specified period of time, used to measure connection activity.                              \\
                    \hline
                \end{tabular}
            }
        }
    \end{table*}




    \section{Tokenization Technique in IoT Application}
    %技術背景說明（Tokenization 的基本原理與應用場景）
    Tokenization is the process of converting raw packet data or traffic feature fields into semantically meaningful token sequences, thereby enabling anomaly detection models to perform contextual understanding and analysis. This technique facilitates the modeling of complex patterns in network traffic by translating low-level features into high-level representations.

    Several representative studies have explored tokenization and related embedding techniques for improving IoT anomaly detection. For example, \citeauthor{9054817} \cite{9054817} proposed vectorized deep learning algorithms, Token2Vec and Flow2Vec, demonstrating significant improvements in prediction accuracy. Similarly, \citeauthor{9154702} \cite{9154702} applied Word2Vec for TF-IDF vectorization on HTTP traffic, combining it with Boosting algorithms to enhance detection accuracy, reduce false alarms, and maintain low computational cost.

    Advancing this line of work, \citeauthor{10633284} \cite{10633284} introduced a CNN-BiLSTM intrusion detection method that integrates tokenization with an attention mechanism to automatically extract sequence features from traffic data, thereby reducing the need for manual feature engineering. Their experiments on vehicle network datasets achieved near-perfect detection accuracy, outperforming existing methods.



    Collectively, these studies confirm the effectiveness of tokenization strategies in IoT anomaly detection. By transforming heterogeneous traffic attributes into unified embedding vectors, these methods empower models to learn behavioral patterns across packet and application layers, which is crucial for building scalable and accurate intrusion detection systems suited for diverse and dynamic IoT environments.



    Table 2.2 shows the comparison of some features in anomaly detection using Tokenization. For example, Protocol = TCP only retains the field name and value, and directly discards other symbols and spaces.

    \begin{table*}[htbp]
        \centering
        \caption{Examples of Field-Value Tokenization in IoT Network Traffic Data}
        \label{tab:tokenization_examples}
        \vspace{0.5em}
        \makebox[\linewidth][c]{
            \renewcommand\arraystretch{1.2}{
                \begin{tabular}{| l | p{10cm} |}
                    \hline
                    \textbf{Feature Field}    & \textbf{Tokenized Representation} \\
                    \hline
                    Protocol = TCP            & Protocol:TCP                      \\
                    \hline
                    Destination Port = 80     & DstPort:80                        \\
                    \hline
                    Flow Duration = 0.32817   & FlowDuration:0.32817              \\
                    \hline
                    Source IP = 192.168.0.1   & SrcIP:192.168.0.1                 \\
                    \hline
                    Payload Bytes = 56        & PayloadBytes:56                   \\
                    \hline
                    Packet Count = 10         & PacketCount:10                    \\
                    \hline
                    Flag = ACK                & Flag:ACK                          \\
                    \hline
                    Destination IP = 10.0.0.5 & DstIP:10.0.0.5                    \\
                    \hline
                \end{tabular}
            }
        }
    \end{table*}


    \newpage
    \section{Hash Embedding in Anomaly Detection} \label{sec:hash_embedding}  %2.3 Hash Embedding in Anomaly Detection
    In \cite{argerich2016hash2vec}, \citeauthor{argerich2016hash2vec} introduced the use of feature hashing through the Hash2Vec technique. By employing two hash functions—one mapping context words to fixed-dimension word vectors and the other assigning sign values—they overlay weighted co-occurrence frequencies directly onto these vectors without requiring any training process, significantly reducing memory usage. Their results show performance comparable to mainstream embedding methods like GloVe.

    Building upon embedding techniques, \citeauthor{10946976} \cite{10946976} proposed a method that integrates a Transformer encoder with masking and an LSTM to capture temporal dependencies, training exclusively on normal data. This approach enhances feature extraction and sequential modeling to detect covert anomalies more effectively. Experimental results indicate improvements of 2.3% in precision, 4.9% in recall, and 3.4% in F1 score, while requiring only 10% of the training data and achieving nearly 17% faster computation during testing compared to DeepLog, highlighting its practical applicability.

    In \cite{argerich2016hash2vec}, \citeauthor{argerich2016hash2vec} a feature hashing method to quickly build word vectors without training. The source and destination IP and port addresses are mapped into low-dimensional vectors, and their pairwise cosine distances are computed. This approach significantly mitigates the sparsity and high dimensionality issues inherent in the original high-dimensional categorical features.

    In \cite{huang2024take}, \citeauthor{huang2024take} proposed  NIDS-GPT Multi-dimensional embedding representation, improves the understanding of the internal structure of the packet, including word embedding, number position embedding and column position embedding, to improve the understanding of the internal structure of the packet. The training goal is to predict the next word in the sequence, and the last word is the label of the packet to complete the classification task.


    Collectively, these studies affirm that hash embedding techniques provide scalable and efficient representations for sparse or categorical IoT traffic features, facilitating rapid and accurate anomaly detection under constrained memory and computational resources.



    \section{Multi-Layer Perceptron in Anomaly Detection}
    Multi-Layer Perceptrons (MLPs)~\cite{lecun2015deep} have been widely adopted in anomaly detection due to their strong capability to model nonlinear relationships between input features and latent patterns. Unlike traditional statistical models that depend on preset thresholds or assumptions about data distributions, MLPs learn complex, high-dimensional feature representations directly from data.

    In recent years, MLP-based approaches have been applied across diverse domains such as network security \cite{marin2005network}, industrial control systems \cite{stouffer2011guide}, and IoT environments \cite{joshitta2016security}. These models typically consist of multiple fully connected layers activated by nonlinear functions like ReLU or sigmoid, enabling the hierarchical learning of semantic features. The resulting outputs are leveraged to differentiate normal from abnormal behavior through reconstruction errors, classification scores, or learned distance measures.

    For example, \citeauthor{elghamrawy2022intrusion} \cite{elghamrawy2022intrusion} implemented a deep learning-based intrusion detection system using an MLP configured for multi-class classification with cross-entropy loss, achieving significant improvements in both efficiency and accuracy.

    Similarly, \citeauthor{esmaeili2023anomaly} \cite{esmaeili2023anomaly} proposed an autoencoder-based prediction model combined with kernel density estimation to autonomously detect anomalies, demonstrating robust detection performance given sufficient normal training data.

    Further, \citeauthor{8264962} \cite{8264962} introduced a hybrid deep learning method combining stacked autoencoders with an MLP classifier, evaluated on the NSL-KDD dataset, attaining an accuracy of 85.42% and outperforming traditional machine learning algorithms such as decision trees and SVM.

    Moreover, \citeauthor{ahmad2021anomaly} \cite{ahmad2021anomaly} proposed an anomaly detection approach leveraging mutual information within deep neural networks. Their comparative study among different deep learning architectures showed accuracy improvements of 0.57–2.6% and false alarm rate reductions of 0.23–7.98%. Notably, using only the top five categorical and numerical features further boosted accuracy by up to 3.45%.

    Collectively, these studies underscore MLPs as a strong foundational model for IoT anomaly detection pipelines, especially when integrated with effective feature engineering and regularization strategies.




    \section{Semantic Vector in IoT Anomaly Detection}
    Semantic vector representations, originally developed in natural language processing (NLP) \cite{resnik2010evaluation}, have been increasingly adopted in anomaly detection tasks due to their capacity to encode complex contextual relationships into fixed-length embeddings. \citeauthor{mikolov2013distributed}~\cite{mikolov2013distributed} proposed the Skip-gram model, which improves training efficiency and vector quality by subsampling high-frequency words and employing negative sampling. To address limitations related to word order sensitivity and the inability to represent idiomatic phrases, an effective phrase recognition method was introduced, enabling the model to learn accurate phrase-level embeddings.

    Building on these advances, \citeauthor{wang2020logevent2vec}~\cite{wang2020logevent2vec} proposed LogEvent2vec, an offline feature extraction framework that applies Word2Vec to capture correlations between log events, directly converting logs into vector representations. They trained supervised classifiers, including random forest, naive Bayes, and neural networks, for anomaly detection. Experimental results indicate that LogEvent2vec reduces computation time by approximately thirty-fold compared to traditional Word2Vec, while achieving improved accuracy. In particular, the combination of barycentric features with random forests yielded the highest F1-score, whereas tf-idf features combined with naive Bayes attained the lowest computational cost.

    These semantic embeddings capture latent associations between fields and behaviors, enabling downstream models to detect subtle deviations from normal patterns. For example, \citeauthor{pan2023flowbert}~\cite{pan2023flowbert} introduced FlowBERT, a Transformer-based model for encrypted traffic classification that extracts semantic features from both payload content and packet length sequences. Their balanced data sampling strategy during pre-training improved model robustness and classification performance beyond existing methods.



    More recently, \citeauthor{hariharan2023detecting}~\cite{hariharan2023detecting} developed the Subword Encoder Neural Network (SEN), which employs an attention-based encoder to learn semantic embeddings at the subword level. The model effectively captures novel log messages and integrates a novel Naive Bayesian Feature Selector (NBFS) for interpretable feature distillation. Their approach significantly outperforms state-of-the-art methods.


    \section{Mahanobis Distance in IoT Anomaly Detection}
    Mahalanobis distance~\cite{de2000mahalanobis} was first proposed by Indian statistician Prasanta Chandra Mahalanobis. It proposed a method to measure the "distance" between points and multidimensional statistical distributions, thus breaking through the limitation of Euclidean distance that cannot adjust scale and correlation.
    Experiments show that when Mahalanobis distance exceeds the normal threshold, abnormal behaviors such as failures or unexpected operations can be detected. The proposed of following classic formula as below.


    \begin{equation}
        d_M(\mathbf{x}) = \sqrt{(\mathbf{x} - \boldsymbol{\mu})^T \, \boldsymbol{\Sigma}^{-1} \, (\mathbf{x} - \boldsymbol{\mu})}
    \end{equation}

    The equation $d_M(\mathbf{x})$ denotes the Mahalanobis distance, where $\mathbf{x}$ is the observation vector, $\boldsymbol{\mu}$ is the mean vector, and $\boldsymbol{\Sigma}$ is the covariance matrix of the distribution.




    In \cite{10415174}, \citeauthor{10415174} proposed FusionNet, a hybrid model that leverages the strengths of multiple machine learning algorithms, including random forests, k-nearest neighbors, support vector machines, and multi-layer perceptrons, to enhance anomaly detection performance. FusionNet's architecture achieves high accuracy and precision, consistently outperforming individual models in terms of accuracy, precision, recall, and F1 score across multiple datasets.

    Similarly, \citeauthor{10622234} \cite{10622234} introduced an anomaly detection method based on Mahalanobis distance. Devices triggered simultaneously are grouped by key actuators, and the distances between configuration states are computed using a k-nearest neighbors model. A control algorithm is applied to estimate the proportion of device failures, effectively reducing the false alarm rate. Experimental results demonstrate that this approach maintains a high detection rate with low false alarms and fast response times.

    More recently, \citeauthor{pillai2024using} \cite{pillai2024using} proposed two anomaly detection techniques employing Mahalanobis distance and Autoencoder models. Their experiments reveal that Autoencoders provide superior generalization and accuracy across varying operating conditions, whereas the Mahalanobis-based method offers computational efficiency and high interpretability. This work highlights the promise of TinyML technologies for real-time anomaly detection applications.






\end{ZhChapter}